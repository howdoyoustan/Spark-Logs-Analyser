{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39bfc902-c583-4725-951d-c9ce3e5bf4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking available models...\n",
      "  - models/gemini-2.5-pro-preview-03-25\n",
      "  - models/gemini-2.5-flash\n",
      "  - models/gemini-2.5-pro-preview-05-06\n",
      "  - models/gemini-2.5-pro-preview-06-05\n",
      "  - models/gemini-2.5-pro\n",
      "  - models/gemini-2.0-flash-exp\n",
      "  - models/gemini-2.0-flash\n",
      "  - models/gemini-2.0-flash-001\n",
      "  - models/gemini-2.0-flash-exp-image-generation\n",
      "  - models/gemini-2.0-flash-lite-001\n",
      "  - models/gemini-2.0-flash-lite\n",
      "  - models/gemini-2.0-flash-lite-preview-02-05\n",
      "  - models/gemini-2.0-flash-lite-preview\n",
      "  - models/gemini-2.0-pro-exp\n",
      "  - models/gemini-2.0-pro-exp-02-05\n",
      "  - models/gemini-exp-1206\n",
      "  - models/gemini-2.0-flash-thinking-exp-01-21\n",
      "  - models/gemini-2.0-flash-thinking-exp\n",
      "  - models/gemini-2.0-flash-thinking-exp-1219\n",
      "  - models/gemini-2.5-flash-preview-tts\n",
      "  - models/gemini-2.5-pro-preview-tts\n",
      "  - models/learnlm-2.0-flash-experimental\n",
      "  - models/gemma-3-1b-it\n",
      "  - models/gemma-3-4b-it\n",
      "  - models/gemma-3-12b-it\n",
      "  - models/gemma-3-27b-it\n",
      "  - models/gemma-3n-e4b-it\n",
      "  - models/gemma-3n-e2b-it\n",
      "  - models/gemini-flash-latest\n",
      "  - models/gemini-flash-lite-latest\n",
      "  - models/gemini-pro-latest\n",
      "  - models/gemini-2.5-flash-lite\n",
      "  - models/gemini-2.5-flash-image-preview\n",
      "  - models/gemini-2.5-flash-image\n",
      "  - models/gemini-2.5-flash-preview-09-2025\n",
      "  - models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  - models/gemini-3-pro-preview\n",
      "  - models/gemini-3-pro-image-preview\n",
      "  - models/nano-banana-pro-preview\n",
      "  - models/gemini-robotics-er-1.5-preview\n",
      "  - models/gemini-2.5-computer-use-preview-10-2025\n"
     ]
    }
   ],
   "source": [
    "# Add this around line 165 (before creating the model)\n",
    "print(\"üîç Checking available models...\")\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(f\"  - {m.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0efc9e-3a55-4449-888e-639d741568c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  WARNING: GOOGLE_API_KEY environment variable not set.\n",
      "üìö Vector DB already contains 789 documents. Skipping ingestion.\n",
      "To force re-ingestion, delete the 'spark_rag_db' folder.\n",
      "\n",
      "==================================================\n",
      "ü§ñ SPARK DIAGNOSTIC CHATBOT READY\n",
      "==================================================\n",
      "Detected Application ID in DB: app-20211011150934-6406\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Application ID to analyze (Press Enter for 'app-20211011150934-6406'):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Context set to: app-20211011150934-6406\n",
      "Type 'quit' to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how long did my job run for ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching logs for App: app-20211011150934-6406...\n",
      "\n",
      "Gemini:\n",
      "The provided logs indicate the following durations for individual jobs:\n",
      "\n",
      "*   **Job 0:** 2.66 seconds\n",
      "*   **Job 1:** 2.27 seconds\n",
      "*   **Job 2:** 0.77 seconds\n",
      "\n",
      "The longest individual job ran for **2.66 seconds**. Without further context on how these jobs are executed within the application (sequentially or in parallel), it is not possible to provide a single \"total job run time\" for the entire application.\n",
      "\n",
      "**Identified Issues and Root Causes:**\n",
      "\n",
      "The most significant issue identified is **severe executor instability**, as highlighted by the `ExecutorChurnSummary`: \"Detected 54 executors with an average lifespan of just 0.53s, indicating severe instability.\" This extreme rate of executor termination indicates a critical underlying problem that can lead to poor performance, task failures, and wasted resources, even if the observed jobs completed successfully.\n",
      "\n",
      "**Specific Technical Root Causes:**\n",
      "\n",
      "1.  **Out-Of-Memory (OOM) Errors:** Executors are likely running out of memory due to data processing exceeding allocated resources. This causes the JVM to crash or the underlying container orchestrator (e.g., YARN, Kubernetes) to terminate the container.\n",
      "2.  **Aggressive Resource Manager Limits:** The cluster's resource manager may be configured with strict memory or CPU limits, leading to premature termination of executor containers if they exceed these thresholds, even before Spark reports an OOM.\n",
      "3.  **Network Instability/Timeouts:** Executors might be losing connection to the Spark Driver due to transient network issues or default network timeouts being too short. This leads the Driver to mark the executors as lost and terminate them.\n",
      "4.  **Insufficient Executor Resources:** The configured `spark.executor.memory` or `spark.executor.cores` might be too low for the workload, causing executors to struggle and crash under load.\n",
      "\n",
      "**Explanation of Spark Terms:**\n",
      "\n",
      "The provided log summaries do not mention 'Data Skew', 'GC Pressure', or 'Shuffle'.\n",
      "\n",
      "**Concrete Configuration Changes:**\n",
      "\n",
      "To address the severe executor instability and churn, consider the following configuration adjustments:\n",
      "\n",
      "1.  **Increase Executor Resources:**\n",
      "    *   **`spark.executor.memory`**: Increase the memory allocated to each executor (e.g., from default 1g to `4g`, `8g`, or more, depending on your data and workload). This provides more memory headroom for data processing.\n",
      "    *   **`spark.executor.cores`**: Increase the number of CPU cores per executor (e.g., from `1` to `2` or `4`). This can help executors process tasks more efficiently if they are CPU-bound.\n",
      "\n",
      "2.  **Adjust Network Timeout:**\n",
      "    *   **`spark.network.timeout`**: Increase this value (e.g., from the default `120s` to `300s` or `600s`). This can help prevent executors from being marked as lost prematurely due to transient network issues between the driver and executors.\n",
      "\n",
      "3.  **Review Cluster Manager Configuration:**\n",
      "    *   **Investigate YARN/Kubernetes/Mesos logs:** It is crucial to examine the logs from your cluster's resource manager for specific reasons why executor containers are being terminated (e.g., `OutOfMemoryError` in YARN container logs, `OOMKilled` events in Kubernetes pods). Adjust container memory requests and limits at the cluster level if they are too restrictive.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how many other application ID's are you aware of ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching logs for App: app-20211011150934-6406...\n",
      "\n",
      "Gemini:\n",
      "Based on the provided log summaries:\n",
      "\n",
      "I am aware of **0 other application IDs** besides `app-20211011150934-6406`.\n",
      "\n",
      "---\n",
      "\n",
      "**Diagnosis for Spark Application: app-20211011150934-6406**\n",
      "\n",
      "The performance logs indicate two critical issues impacting the application:\n",
      "\n",
      "1.  **Severe Executor Instability / Churn:**\n",
      "    *   **Root Cause:** The logs report 54 executors with an average lifespan of just 0.53 seconds, which is a strong indicator of repeated executor failures, most commonly due to OutOfMemoryError (OOM) exceptions. This leads to wasted resources, re-computation, and overall application instability.\n",
      "    *   **Suggested Configuration Change:**\n",
      "        *   Increase `spark.executor.memory` to provide more heap space for executors (e.g., `spark.executor.memory 20g`).\n",
      "        *   Consider increasing `spark.executor.memoryOverhead` to account for off-heap memory usage by the JVM and external libraries (e.g., `spark.executor.memoryOverhead 4g`).\n",
      "\n",
      "2.  **Persistent Deserialization Bottleneck:**\n",
      "    *   **Root Cause:** Multiple stages (0, 2, 4, 5) show a significant percentage of runtime spent on deserialization (up to 100.2% in Stage 4). Deserialization is the process of converting data from a byte stream (e.g., received over the network or read from disk) back into in-memory Java/Scala objects. High deserialization time indicates that the application is spending a disproportionate amount of CPU cycles on this conversion, potentially due to inefficient serialization formats, large object graphs, or frequent data transfers.\n",
      "    *   **Suggested Configuration Change:**\n",
      "        *   Enable and configure Kryo serialization, which is generally more efficient than Java serialization:\n",
      "            *   `spark.serializer org.apache.spark.serializer.KryoSerializer`\n",
      "            *   If using custom classes, register them with Kryo for optimal performance: `spark.kryo.registrator <your.KryoRegistratorClass>`\n",
      "\n",
      "The logs do not mention 'Data Skew', 'GC Pressure', or 'Shuffle' explicitly.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what was the most prominent issue in my jobs ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching logs for App: app-20211011150934-6406...\n",
      "\n",
      "Gemini:\n",
      "The most prominent issue in your Spark application is the **critical failure of executors to launch due to insufficient disk space on the nodes**. This directly led to severe instability, evidenced by 54 executors failing and having an average lifespan of just 0.53 seconds.\n",
      "\n",
      "**Technical Root Cause:**\n",
      "Executors are failing at startup because the underlying cluster nodes where they attempt to launch do not have adequate local disk space available. This prevents them from properly initializing their working directories, temporary files, or spill space, leading to immediate termination.\n",
      "\n",
      "**Configuration Change Suggestion:**\n",
      "To address this, you should adjust the `spark.local.dir` configuration. This property specifies the directories where Spark should use local disk.\n",
      "\n",
      "**Concrete Configuration Change:**\n",
      "*   **`spark.local.dir`**: Configure this property to point to a path on the cluster nodes that has significantly more available disk space. For example:\n",
      "    `spark.conf.set(\"spark.local.dir\", \"/path/to/larger/disk/space\")`\n",
      "\n",
      "    Ensure that this path exists and has sufficient write permissions and capacity on all worker nodes. If increasing the space for `spark.local.dir` is not feasible, the underlying infrastructure may require provisioning with more disk space per node.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 320\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to exit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import chromadb\n",
    "import google.generativeai as genai\n",
    "from statistics import median\n",
    "from typing import List, Dict\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURATION\n",
    "# ==========================================\n",
    "# Export this in your terminal: export GOOGLE_API_KEY=\"your_key\"\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\") \n",
    "DB_PATH = \"./spark_rag_db\" # Where vectors will be saved on disk\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"‚ö†Ô∏è  WARNING: GOOGLE_API_KEY environment variable not set.\")\n",
    "    genai.configure(api_key=\"AIzaSyDM2QBkfDldek1Ey52-8ANg4T_1NqLATpo\") \n",
    "else:\n",
    "    genai.configure(api_key=API_KEY)\n",
    "\n",
    "# ==========================================\n",
    "# 1. PARSING LOGIC (Your Code)\n",
    "# ==========================================\n",
    "\n",
    "class SparkLogAnalysis:\n",
    "    \"\"\"A container object for all parsed summaries from a Spark event log.\"\"\"\n",
    "    def __init__(self, log_file_path):\n",
    "        self.application_id = \"unknown_app\"\n",
    "        self.log_file = os.path.basename(log_file_path)\n",
    "        self.job_summaries = []\n",
    "        self.stage_summaries = []\n",
    "        self.application_summaries = {}\n",
    "\n",
    "    def set_application_id(self, app_id):\n",
    "        if app_id:\n",
    "            self.application_id = app_id\n",
    "\n",
    "    def add_summary(self, summary_dict):\n",
    "        if not summary_dict: return\n",
    "        event_type = summary_dict.get(\"event_type\")\n",
    "        summary_dict[\"application_id\"] = self.application_id\n",
    "\n",
    "        if event_type == \"JobPerformanceSummary\":\n",
    "            self.job_summaries.append(summary_dict)\n",
    "        elif event_type == \"StagePerformanceSummary\":\n",
    "            self.stage_summaries.append(summary_dict)\n",
    "        else:\n",
    "            self.application_summaries[event_type] = summary_dict\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"application_id\": self.application_id,\n",
    "            \"log_file\": self.log_file,\n",
    "            \"job_summaries\": self.job_summaries,\n",
    "            \"stage_summaries\": self.stage_summaries,\n",
    "            \"application_summaries\": self.application_summaries\n",
    "        }\n",
    "\n",
    "def analyze_spark_log(log_file_path):\n",
    "    \"\"\"Parses a single Spark event log.\"\"\"\n",
    "    analysis_object = SparkLogAnalysis(log_file_path)\n",
    "    stage_data = {}\n",
    "    job_data = {}\n",
    "    executor_lifecycle = {}\n",
    "    disk_related_executor_failures = {}\n",
    "    blacklisted_executors = []\n",
    "\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    event = json.loads(line)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "                event_type = event.get(\"Event\")\n",
    "                \n",
    "                if event_type == \"SparkListenerApplicationStart\":\n",
    "                    analysis_object.set_application_id(event.get(\"App ID\"))\n",
    "                \n",
    "                elif event_type == \"SparkListenerExecutorAdded\":\n",
    "                    executor_id, timestamp = event.get(\"Executor ID\"), event.get(\"Timestamp\")\n",
    "                    executor_lifecycle.setdefault(executor_id, {})['add_time'] = timestamp\n",
    "\n",
    "                elif event_type == \"SparkListenerExecutorRemoved\":\n",
    "                    executor_id, timestamp = event.get(\"Executor ID\"), event.get(\"Timestamp\")\n",
    "                    reason = event.get(\"Removed Reason\", \"\")\n",
    "                    executor_lifecycle.setdefault(executor_id, {})['remove_time'] = timestamp\n",
    "                    if \"no space left on device\" in reason.lower() or \"disk\" in reason.lower():\n",
    "                        disk_related_executor_failures.setdefault(reason, {\"count\": 0, \"samples\": []})\n",
    "                        disk_related_executor_failures[reason][\"count\"] += 1\n",
    "                        if len(disk_related_executor_failures[reason][\"samples\"]) < 3:\n",
    "                            disk_related_executor_failures[reason][\"samples\"].append({\"executor_id\": executor_id, \"timestamp\": timestamp})\n",
    "\n",
    "                elif event_type == \"SparkListenerExecutorBlacklisted\":\n",
    "                    blacklisted_executors.append({\"executor_id\": event.get(\"Executor ID\"), \"timestamp\": event.get(\"Timestamp\"), \"reason\": f\"Blacklisted for {event.get('Task ID')} task failures\"})\n",
    "\n",
    "                elif event_type == \"SparkListenerJobStart\":\n",
    "                    job_id = event.get(\"Job ID\")\n",
    "                    job_data[job_id] = {\"start_time\": event.get(\"Submission Time\")}\n",
    "\n",
    "                elif event_type == \"SparkListenerJobEnd\":\n",
    "                    job_id = event.get(\"Job ID\")\n",
    "                    if job_id in job_data:\n",
    "                        duration_ms = event.get(\"Completion Time\") - job_data[job_id][\"start_time\"]\n",
    "                        job_result = event.get(\"Job Result\", {}).get(\"Result\")\n",
    "                        analysis_object.add_summary({ \"event_type\": \"JobPerformanceSummary\", \"job_id\": job_id, \"status\": job_result, \"duration_s\": duration_ms / 1000, \"summary\": f\"Job {job_id} finished with status {job_result} in {duration_ms / 1000:.2f} seconds.\" })\n",
    "                        del job_data[job_id]\n",
    "\n",
    "                elif event_type == \"SparkListenerTaskEnd\":\n",
    "                    stage_id = event.get(\"Stage ID\")\n",
    "                    if stage_id is not None:\n",
    "                        stage_data.setdefault(stage_id, {\"tasks\": [], \"failed_task_count\": 0})\n",
    "                        if event.get(\"Task End Reason\", {}).get(\"Reason\") != \"Success\": stage_data[stage_id][\"failed_task_count\"] += 1\n",
    "                        task_info, task_metrics = event.get(\"Task Info\", {}), event.get(\"Task Metrics\", {})\n",
    "                        duration_ms = task_info.get(\"Finish Time\", 0) - task_info.get(\"Launch Time\", 0)\n",
    "                        stage_data[stage_id][\"tasks\"].append({ \"duration_ms\": duration_ms, \"jvm_gc_time_ms\": task_metrics.get(\"JVM GC Time\", 0), \"executor_run_time_ms\": task_metrics.get(\"Executor Run Time\", 1), \"executor_deserialize_time_ms\": task_metrics.get(\"Executor Deserialize Time\", 0), \"shuffle_fetch_wait_time_ms\": task_metrics.get(\"Shuffle Read Metrics\", {}).get(\"Fetch Wait Time\", 0), \"memory_spilled_bytes\": task_metrics.get(\"Memory Bytes Spilled\", 0), \"disk_spilled_bytes\": task_metrics.get(\"Disk Bytes Spilled\", 0), })\n",
    "\n",
    "                elif event_type == \"SparkListenerStageCompleted\":\n",
    "                    stage_id = event.get(\"Stage Info\", {}).get(\"Stage ID\")\n",
    "                    if stage_id in stage_data and len(stage_data[stage_id][\"tasks\"]) > 0:\n",
    "                        tasks, failed_task_count = stage_data[stage_id][\"tasks\"], stage_data[stage_id][\"failed_task_count\"]\n",
    "                        task_durations = [t[\"duration_ms\"] for t in tasks]\n",
    "                        total_duration, total_gc_time, total_runtime = sum(task_durations), sum(t[\"jvm_gc_time_ms\"] for t in tasks), sum(t[\"executor_run_time_ms\"] for t in tasks)\n",
    "                        total_deserialize_time, total_fetch_wait_time = sum(t[\"executor_deserialize_time_ms\"] for t in tasks), sum(t[\"shuffle_fetch_wait_time_ms\"] for t in tasks)\n",
    "                        total_spilled_bytes = sum(t[\"memory_spilled_bytes\"] for t in tasks) + sum(t[\"disk_spilled_bytes\"] for t in tasks)\n",
    "                        summary_parts, potential_issues = [f\"Stage {stage_id} completed with {len(tasks)} tasks.\"], []\n",
    "                        if failed_task_count > 0: summary_parts.append(f\"It experienced {failed_task_count} task failures that required retries.\"); potential_issues.append(\"TASK_FAILURES\")\n",
    "                        max_duration, median_duration = max(task_durations), median(task_durations)\n",
    "                        if max_duration > 3 * median_duration and max_duration > 20000: potential_issues.append(\"DATA_SKEW\"); summary_parts.append(f\"Detected potential data skew. Max task duration: {max_duration/1000:.2f}s, median: {median_duration/1000:.2f}s.\")\n",
    "                        if total_runtime > 0 and (total_gc_time / total_runtime) > 0.10: potential_issues.append(\"HIGH_GC_PRESSURE\"); summary_parts.append(f\"High JVM GC pressure detected ({ (total_gc_time / total_runtime) * 100:.1f}% of runtime).\")\n",
    "                        if total_spilled_bytes > 0: potential_issues.append(\"DATA_SPILL\"); summary_parts.append(f\"Detected data spilling to disk ({total_spilled_bytes / (1024*1024):.2f} MB).\")\n",
    "                        if total_duration > 0 and (total_fetch_wait_time / total_duration) > 0.25: potential_issues.append(\"SHUFFLE_BOTTLENECK\"); summary_parts.append(f\"Significant shuffle bottleneck, tasks spent {(total_fetch_wait_time / total_duration) * 100:.1f}% of time waiting for data.\")\n",
    "                        if total_runtime > 0 and (total_deserialize_time / total_runtime) > 0.15: potential_issues.append(\"DESERIALIZATION_BOTTLENECK\"); summary_parts.append(f\"High deserialization time ({(total_deserialize_time / total_runtime) * 100:.1f}% of runtime).\")\n",
    "                        analysis_object.add_summary({ \"event_type\": \"StagePerformanceSummary\", \"stage_id\": stage_id, \"metrics\": { \"task_count\": len(tasks), \"failed_task_count\": failed_task_count, \"max_task_duration_ms\": max_duration, \"median_task_duration_ms\": median_duration, \"total_spilled_mb\": total_spilled_bytes / (1024*1024) }, \"summary\": \" \".join(summary_parts), \"potential_issues\": potential_issues if potential_issues else [\"NONE\"] })\n",
    "\n",
    "        if disk_related_executor_failures:\n",
    "            total_failures = sum(v['count'] for v in disk_related_executor_failures.values())\n",
    "            analysis_object.add_summary({ \"event_type\": \"ExecutorDiskFailureSummary\", \"total_failures\": total_failures, \"summary\": f\"A critical error occurred where {total_failures} executors failed to launch due to running out of disk space on the nodes.\", \"failures_by_reason\": disk_related_executor_failures })\n",
    "        \n",
    "        short_lived_executors = []\n",
    "        churn_threshold_ms = 60000 \n",
    "        for exec_id, times in executor_lifecycle.items():\n",
    "            if 'add_time' in times and 'remove_time' in times and (times['remove_time'] - times['add_time']) < churn_threshold_ms:\n",
    "                short_lived_executors.append({\"executor_id\": exec_id, \"lifespan_s\": (times['remove_time'] - times['add_time']) / 1000})\n",
    "        if short_lived_executors:\n",
    "            avg_lifespan_s = sum(e['lifespan_s'] for e in short_lived_executors) / len(short_lived_executors)\n",
    "            analysis_object.add_summary({ \"event_type\": \"ExecutorChurnSummary\", \"total_churn_events\": len(short_lived_executors), \"summary\": f\"Detected {len(short_lived_executors)} executors with an average lifespan of just {avg_lifespan_s:.2f}s, indicating severe instability.\", \"average_lifespan_s\": round(avg_lifespan_s, 2), \"sample_churned_executors\": short_lived_executors[:3] })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "    return analysis_object\n",
    "\n",
    "# ==========================================\n",
    "# 2. VECTORIZATION (ChromaDB Integration)\n",
    "# ==========================================\n",
    "\n",
    "def get_chroma_collection():\n",
    "    \"\"\"Returns a persistent ChromaDB collection.\"\"\"\n",
    "    # Using PersistentClient to save data to disk so we don't re-index every run\n",
    "    client = chromadb.PersistentClient(path=DB_PATH)\n",
    "    # Using the default embedding model (all-MiniLM-L6-v2)\n",
    "    return client.get_or_create_collection(name=\"spark_logs\")\n",
    "\n",
    "def ingest_logs(log_directory):\n",
    "    \"\"\"Parses logs and ingests them into ChromaDB.\"\"\"\n",
    "    collection = get_chroma_collection()\n",
    "    \n",
    "    # Check if we already have data (optional optimization)\n",
    "    if collection.count() > 0:\n",
    "        print(f\"üìö Vector DB already contains {collection.count()} documents. Skipping ingestion.\")\n",
    "        print(\"To force re-ingestion, delete the 'spark_rag_db' folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìÇ Processing logs in: {log_directory}\")\n",
    "    all_analyses = []\n",
    "\n",
    "    for filename in os.listdir(log_directory):\n",
    "        full_path = os.path.join(log_directory, filename)\n",
    "        if os.path.isfile(full_path):\n",
    "            print(f\"   - Parsing {filename}...\")\n",
    "            analysis = analyze_spark_log(full_path)\n",
    "            if analysis:\n",
    "                all_analyses.append(analysis)\n",
    "\n",
    "    print(\"üß© Vectorizing and storing data...\")\n",
    "    documents, metadatas, ids = [], [], []\n",
    "\n",
    "    for analysis in all_analyses:\n",
    "        # Flatten the object\n",
    "        summaries = (analysis.job_summaries + \n",
    "                     analysis.stage_summaries + \n",
    "                     list(analysis.application_summaries.values()))\n",
    "\n",
    "        for i, summary in enumerate(summaries):\n",
    "            # 1. Text to Embed\n",
    "            documents.append(summary[\"summary\"])\n",
    "            \n",
    "            # 2. Metadata Cleaning (Chroma requires simple types)\n",
    "            meta = summary.copy()\n",
    "            del meta[\"summary\"]\n",
    "            \n",
    "            # Convert list/dict fields to strings for metadata storage\n",
    "            for key, val in meta.items():\n",
    "                if isinstance(val, (list, dict)):\n",
    "                    meta[key] = str(val)\n",
    "            \n",
    "            metadatas.append(meta)\n",
    "            ids.append(f\"{analysis.application_id}_{i}\")\n",
    "\n",
    "    if documents:\n",
    "        collection.add(documents=documents, metadatas=metadatas, ids=ids)\n",
    "        print(f\"‚úÖ Successfully ingested {len(documents)} log events into ChromaDB.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid log events found to ingest.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. LLM ORCHESTRATOR (The RAG Logic)\n",
    "# ==========================================\n",
    "\n",
    "def get_gemini_response(user_query, app_id, collection):\n",
    "    \"\"\"\n",
    "    1. Retrieval: Search ChromaDB filtered by app_id.\n",
    "    2. Augmentation: Build a prompt with the search results.\n",
    "    3. Generation: Call Gemini API.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Searching logs for App: {app_id}...\")\n",
    "    \n",
    "    # 1. RETRIEVAL\n",
    "    # We query for top 5 most relevant log summaries for this specific app\n",
    "    results = collection.query(\n",
    "        query_texts=[user_query],\n",
    "        n_results=5,\n",
    "        where={\"application_id\": app_id} \n",
    "    )\n",
    "\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    retrieved_meta = results['metadatas'][0]\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        return \"I couldn't find any specific log events matching your question for this application ID.\"\n",
    "\n",
    "    # 2. AUGMENTATION (Context Construction)\n",
    "    context_parts = []\n",
    "    for doc, meta in zip(retrieved_docs, retrieved_meta):\n",
    "        # We combine the text summary with key metadata tags for the LLM\n",
    "        # e.g. \"Event: JobPerformanceSummary | Issues: DATA_SKEW | Text: Job 2 finished...\"\n",
    "        info_tag = f\"[{meta.get('event_type', 'Event')}]\"\n",
    "        issue_tag = f\"[Issues: {meta.get('potential_issues', 'None')}]\"\n",
    "        context_parts.append(f\"{info_tag} {issue_tag}\\nLog Summary: {doc}\")\n",
    "\n",
    "    context_str = \"\\n---\\n\".join(context_parts)\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an expert Apache Spark Log Diagnostician. \n",
    "    You are analyzing performance logs for Spark Application: {app_id}.\n",
    "\n",
    "    Here are the most relevant log summaries retrieved from the system:\n",
    "    \n",
    "    {context_str}\n",
    "\n",
    "    USER QUESTION: \"{user_query}\"\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    1. specific technical root causes based ONLY on the provided log summaries.\n",
    "    2. If the logs mention 'Data Skew', 'GC Pressure', or 'Shuffle', explain what that means.\n",
    "    3. Suggest a concrete configuration change (e.g., 'Increase spark.executor.memory', 'Adjust spark.sql.shuffle.partitions').\n",
    "    4. Keep the tone professional and concise.\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. GENERATION\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        response = model.generate_content(system_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error communicating with Gemini API: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # A. Setup paths\n",
    "    # CHANGE THIS to your actual log folder path\n",
    "    LOG_DIR = r\"C:\\Users\\ddev\\Documents\\projects\\spark-event-logs\\test-logs\"\n",
    "    \n",
    "    if not os.path.exists(LOG_DIR):\n",
    "        print(f\"‚ùå Error: Log directory '{LOG_DIR}' does not exist.\")\n",
    "        exit()\n",
    "\n",
    "    # B. Ingest Logs (only runs if DB is empty)\n",
    "    ingest_logs(LOG_DIR)\n",
    "    \n",
    "    # C. Get the collection for querying\n",
    "    collection = get_chroma_collection()\n",
    "    \n",
    "    # D. Interactive Chat Loop\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ü§ñ SPARK DIAGNOSTIC CHATBOT READY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Simulating a user selecting an App ID (In a real UI, this is a dropdown)\n",
    "    # For now, let's grab the first App ID available in the DB for testing\n",
    "    existing_ids = collection.get(limit=1)['metadatas']\n",
    "    if existing_ids:\n",
    "        default_app = existing_ids[0].get('application_id')\n",
    "        print(f\"Detected Application ID in DB: {default_app}\")\n",
    "        target_app_id = input(f\"Enter Application ID to analyze (Press Enter for '{default_app}'): \") or default_app\n",
    "    else:\n",
    "        print(\"No data in DB. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"\\nüí¨ Context set to: {target_app_id}\")\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['quit', 'exit']:\n",
    "            break\n",
    "        \n",
    "        answer = get_gemini_response(user_input, target_app_id, collection)\n",
    "        print(f\"\\nGemini:\\n{answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974366f-ef58-4183-b969-5fc102477093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
